{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import hdf5_getters as GETTERS\n",
    "#h5 = GETTERS.open_h5_file_read('TRAXLZU12903D05F94.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import hdf5_getters as GETTERS\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open_file in module tables.file:\n",
      "\n",
      "open_file(filename, mode='r', title='', root_uep='/', filters=None, **kwargs)\n",
      "    Open a PyTables (or generic HDF5) file and return a File object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : str\n",
      "        The name of the file (supports environment variable expansion).\n",
      "        It is suggested that file names have any of the .h5, .hdf or\n",
      "        .hdf5 extensions, although this is not mandatory.\n",
      "    mode : str\n",
      "        The mode to open the file. It can be one of the\n",
      "        following:\n",
      "    \n",
      "            * *'r'*: Read-only; no data can be modified.\n",
      "            * *'w'*: Write; a new file is created (an existing file\n",
      "              with the same name would be deleted).\n",
      "            * *'a'*: Append; an existing file is opened for reading and\n",
      "              writing, and if the file does not exist it is created.\n",
      "            * *'r+'*: It is similar to 'a', but the file must already\n",
      "              exist.\n",
      "    \n",
      "    title : str\n",
      "        If the file is to be created, a TITLE string attribute will be\n",
      "        set on the root group with the given value. Otherwise, the\n",
      "        title will be read from disk, and this will not have any effect.\n",
      "    root_uep : str\n",
      "        The root User Entry Point. This is a group in the HDF5 hierarchy\n",
      "        which will be taken as the starting point to create the object\n",
      "        tree. It can be whatever existing group in the file, named by\n",
      "        its HDF5 path. If it does not exist, an HDF5ExtError is issued.\n",
      "        Use this if you do not want to build the *entire* object tree,\n",
      "        but rather only a *subtree* of it.\n",
      "    \n",
      "        .. versionchanged:: 3.0\n",
      "           The *rootUEP* parameter has been renamed into *root_uep*.\n",
      "    \n",
      "    filters : Filters\n",
      "        An instance of the Filters (see :ref:`FiltersClassDescr`) class\n",
      "        that provides information about the desired I/O filters\n",
      "        applicable to the leaves that hang directly from the *root group*,\n",
      "        unless other filter properties are specified for these leaves.\n",
      "        Besides, if you do not specify filter properties for child groups,\n",
      "        they will inherit these ones, which will in turn propagate to\n",
      "        child nodes.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    In addition, it recognizes the (lowercase) names of parameters\n",
      "    present in :file:`tables/parameters.py` as additional keyword\n",
      "    arguments.\n",
      "    See :ref:`parameter_files` for a detailed info on the supported\n",
      "    parameters.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "        If you need to deal with a large number of nodes in an\n",
      "        efficient way, please see :ref:`LRUOptim` for more info and\n",
      "        advices about the integrated node cache engine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tables.open_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = tables.open_file(\"file_1.h5\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ARXR32B1187FB57099'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GETTERS.get_artist_id(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673, 12)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(GETTERS.get_segments_timbre(f).shape)\n",
    "print(GETTERS.get_num_songs(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sec_file = tables.open_file(\"../MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\",mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GETTERS.get_segments_timbre(sec_file).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAAAEF128F4273421.h5\n",
      "(821, 12)\n",
      "TRAAAAW128F429D538.h5\n",
      "(971, 12)\n",
      "TRAAARJ128F9320760.h5\n",
      "(912, 12)\n",
      "TRAAAVG12903CFA543.h5\n",
      "(1406, 12)\n",
      "TRAAAMQ128F1460CD3.h5\n",
      "(481, 12)\n",
      "TRAAABD128F429CF47.h5\n",
      "(550, 12)\n",
      "TRAAAPK128E0786D96.h5\n",
      "(588, 12)\n",
      "TRAAAFD128F92F423A.h5\n",
      "(673, 12)\n",
      "TRAAAVO128F93133D4.h5\n",
      "(699, 12)\n",
      "TRAAAMO128F1481E7F.h5\n",
      "(835, 12)\n",
      "TRAAADZ128F9348C2E.h5\n",
      "(562, 12)\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"../MillionSongSubset/data/A/A/A/\"\n",
    "for file in os.listdir(dir_name):\n",
    "    print(file)\n",
    "    sec_file = tables.open_file(dir_name+file,mode=\"r\")\n",
    "    print(GETTERS.get_segments_timbre(sec_file).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h5_f = h5py.File('file_1.h5', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE b'H5 Song File'\n",
      "CLASS b'GROUP'\n",
      "VERSION b'1.0'\n",
      "PYTABLES_FORMAT_VERSION b'2.0'\n",
      "FILTERS 65793\n",
      "analysis <HDF5 group \"/analysis\" (16 members)>\n",
      "metadata <HDF5 group \"/metadata\" (5 members)>\n",
      "musicbrainz <HDF5 group \"/musicbrainz\" (3 members)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in h5_f.attrs.keys():\n",
    "    print(k, h5_f.attrs[k])\n",
    "    \n",
    "for i in h5_f.items():\n",
    "    print(i[0], i[1])\n",
    "\n",
    "songs = h5_f.get('metadata').get('songs')\n",
    "\n",
    "songs.attrs['NROWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp = h5py.h5.ByteStringContext(f.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5py.h5.ByteStringContext at 0x10913abe0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_f = open('file_1.h5', 'rb')\n",
    "tmp = h5py.h5.ByteStringContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import hdf5_getters as GETTERS\n",
    "import os\n",
    "import string\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_target_track_id_list():\n",
    "    # Read the track ids with top 100 tags\n",
    "    with open('new_complet_msd_ids.txt', 'r') as fd:\n",
    "        data = fd.read()\n",
    "    \n",
    "    return data.split(',')\n",
    "\n",
    "def put_target_track_into_buckets(target_track_id_list):\n",
    "    \n",
    "    buckets = {}\n",
    "    \n",
    "    for upper_letter in string.ascii_uppercase:\n",
    "         buckets[upper_letter] = list(filter(lambda track_id: track_id[2] == upper_letter, target_track_id_list))\n",
    "            \n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82321\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "target_track_id_list = read_target_track_id_list()\n",
    "print(len(target_track_id_list))\n",
    "\n",
    "target_track_id_list = sorted(target_track_id_list)\n",
    "\n",
    "target_tracks_buckets = put_target_track_into_buckets(target_track_id_list)\n",
    "print(len(target_tracks_buckets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 3163\n",
      "B 2960\n",
      "C 2937\n",
      "D 3377\n",
      "E 3281\n",
      "F 3109\n",
      "G 2842\n",
      "H 2961\n",
      "I 3013\n",
      "J 3312\n",
      "K 3499\n",
      "L 3200\n",
      "M 2838\n",
      "N 3180\n",
      "O 3441\n",
      "P 3253\n",
      "Q 3104\n",
      "R 3082\n",
      "S 3274\n",
      "T 3157\n",
      "U 3233\n",
      "V 3292\n",
      "W 2920\n",
      "X 3413\n",
      "Y 3554\n",
      "Z 2926\n"
     ]
    }
   ],
   "source": [
    "for bucket in sorted(target_tracks_buckets):\n",
    "    print(bucket, len(target_tracks_buckets[bucket]))\n",
    "    \n",
    "#     print(target_tracks_buckets[bucket][:10])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_files_in_bucket(bucket):\n",
    "\n",
    "    feature_file_handle = open('%s.txt' % (bucket), 'w')\n",
    "\n",
    "    cnt = 0\n",
    "    for track_id in target_tracks_buckets[bucket]:\n",
    "        h5_file_path = track_id[2] + '/' + \\\n",
    "                        track_id[3] + '/' + \\\n",
    "                        track_id[4] + '/' + \\\n",
    "                        track_id + '.h5'\n",
    "\n",
    "        with tables.open_file('./' + h5_file_path, mode=\"r\") as h5_file_handle:\n",
    "\n",
    "            mfcc_vec = GETTERS.get_segments_timbre(h5_file_handle).reshape(-1).tolist()\n",
    "            mfcc_vec.insert(0, track_id)\n",
    "\n",
    "            to_str_mfcc_vec = list(map(lambda v: str(v), mfcc_vec))\n",
    "            feature_file_handle.write(','.join(to_str_mfcc_vec) + '\\n')\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        if cnt % 200 == 0:\n",
    "            print('Processed %d files' % (cnt))\n",
    "\n",
    "    feature_file_handle.close()\n",
    "    \n",
    "    print('Successfully extracted %d files' % (cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/A.tar.gz\n",
      "3163 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3163 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/A.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/B.tar.gz\n",
      "2960 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2960 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/B.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/C.tar.gz\n",
      "2937 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2937 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/C.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/D.tar.gz\n",
      "3377 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3377 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/D.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/E.tar.gz\n",
      "3281 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3281 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/E.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/F.tar.gz\n",
      "3109 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3109 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/F.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/G.tar.gz\n",
      "2842 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2842 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/G.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/H.tar.gz\n",
      "2961 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2961 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/H.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/I.tar.gz\n",
      "3013 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3013 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/I.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/J.tar.gz\n",
      "3312 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3312 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/J.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/K.tar.gz\n",
      "3499 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Processed 3400 files\n",
      "Successfully extracted 3499 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/K.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/L.tar.gz\n",
      "3200 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3200 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/L.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/M.tar.gz\n",
      "2838 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2838 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/M.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/N.tar.gz\n",
      "3180 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3180 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/N.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/O.tar.gz\n",
      "3441 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Processed 3400 files\n",
      "Successfully extracted 3441 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/O.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/P.tar.gz\n",
      "3253 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3253 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/P.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/Q.tar.gz\n",
      "3104 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3104 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/Q.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/S.tar.gz\n",
      "3274 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3274 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/S.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/T.tar.gz\n",
      "3157 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Successfully extracted 3157 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/T.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/U.tar.gz\n",
      "3233 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3233 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/U.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/V.tar.gz\n",
      "3292 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Successfully extracted 3292 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/V.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/W.tar.gz\n",
      "2920 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2920 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/W.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/X.tar.gz\n",
      "3413 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Processed 3400 files\n",
      "Successfully extracted 3413 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/X.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/Y.tar.gz\n",
      "3554 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Processed 3000 files\n",
      "Processed 3200 files\n",
      "Processed 3400 files\n",
      "Successfully extracted 3554 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/Y.tar.gz\n",
      "Working on /Volumes/NETAC/Scalable_ML_data_MSD/Z.tar.gz\n",
      "2926 files in total to process\n",
      "Finished extracting tgz file\n",
      "Processed 200 files\n",
      "Processed 400 files\n",
      "Processed 600 files\n",
      "Processed 800 files\n",
      "Processed 1000 files\n",
      "Processed 1200 files\n",
      "Processed 1400 files\n",
      "Processed 1600 files\n",
      "Processed 1800 files\n",
      "Processed 2000 files\n",
      "Processed 2200 files\n",
      "Processed 2400 files\n",
      "Processed 2600 files\n",
      "Processed 2800 files\n",
      "Successfully extracted 2926 files\n",
      "Finished /Volumes/NETAC/Scalable_ML_data_MSD/Z.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for fn in glob.glob(os.path.join('/Volumes/NETAC/Scalable_ML_data_MSD/', '*.tar.gz')):\n",
    "    \n",
    "    print('Working on %s' % (fn))\n",
    "    \n",
    "    bucket = fn.split('/')[-1][0]\n",
    "    files_to_extract = target_tracks_buckets[bucket]\n",
    "    \n",
    "    print('%d files in total to process' % (len(files_to_extract)))\n",
    "    os.system('tar -zxvf %s -C .' % (fn))\n",
    "    print('Finished extracting tgz file')\n",
    "    \n",
    "    extract_files_in_bucket(bucket)\n",
    "    \n",
    "    os.system('rm -rf %s' % (bucket))\n",
    "    print('Finished %s' % (fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
